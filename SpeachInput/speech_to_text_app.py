import gradio as gr
import speech_recognition as sr
from typing import Union, Tuple, Optional
import numpy as np

class SpeechToTextApp:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–µ—á–∏ –≤ —Ç–µ–∫—Å—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Gradio.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏ –∑–∞–≥—Ä—É–∑–∫—É –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤.
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è —Ä–µ—á–∏."""
        self.recognizer = sr.Recognizer()
    
    def transcribe_audio(self, audio: Optional[Union[str, Tuple[int, np.ndarray]]]) -> str:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç.
        
        Args:
            audio: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ –∫–æ—Ä—Ç–µ–∂ (—á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏, –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ)
            
        Returns:
            str: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        """
        if audio is None:
            return "–ê—É–¥–∏–æ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ"
        
        try:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if isinstance(audio, str):
                # –≠—Ç–æ —Ñ–∞–π–ª
                with sr.AudioFile(audio) as source:
                    audio_data = self.recognizer.record(source)
            else:
                # –≠—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ (sample_rate, numpy_array)
                sr_value, y = audio
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ–Ω–æ, –µ—Å–ª–∏ —Å—Ç–µ—Ä–µ–æ
                if y.ndim > 1:
                    y = y.mean(axis=1)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                import tempfile
                import wave
                import numpy as np
                
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    with wave.open(temp_file.name, 'wb') as wf:
                        wf.setnchannels(1)  # –º–æ–Ω–æ
                        wf.setsampwidth(2)  # 16-bit
                        wf.setframerate(sr_value)
                        wf.writeframes((y * 32767).astype(np.int16).tobytes())
                    
                    with sr.AudioFile(temp_file.name) as source:
                        audio_data = self.recognizer.record(source)
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
            text = self.recognizer.recognize_google(audio_data, language='ru-RU')
            return text
            
        except sr.UnknownValueError:
            return "–†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞"
        except sr.RequestError as e:
            return f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}"
        except Exception as e:
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"
    
    def create_interface(self):
        """
        –°–æ–∑–¥–∞–µ—Ç Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.
        
        Returns:
            gr.Blocks: –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
        """
        with gr.Blocks(title="–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Ç–µ–∫—Å—Ç") as demo:
            gr.Markdown("# üé§ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Ç–µ–∫—Å—Ç")
            gr.Markdown("–ó–∞–ø–∏—à–∏—Ç–µ –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª, –∑–∞—Ç–µ–º –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.")
            
            with gr.Row():
                audio_input = gr.Audio(
                    sources=["microphone", "upload"],
                    type="filepath",
                    label="–ê—É–¥–∏–æ–≤—Ö–æ–¥",
                    interactive=True
                )
            
            with gr.Row():
                convert_btn = gr.Button("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Ç–µ–∫—Å—Ç", variant="primary")
            
            with gr.Row():
                text_output = gr.Textbox(
                    label="–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç",
                    placeholder="–ó–¥–µ—Å—å –ø–æ—è–≤–∏—Ç—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç...",
                    lines=4,
                    max_lines=10
                )
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏
            convert_btn.click(
                fn=self.transcribe_audio,
                inputs=audio_input,
                outputs=text_output
            )
        
        return demo
    
    def launch(self, **kwargs):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.
        
        Args:
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è launch()
        """
        demo = self.create_interface()
        demo.launch(**kwargs)

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    import numpy as np
    
    app = SpeechToTextApp()
    app.launch(share=True)  # share=True –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—É–±–ª–∏—á–Ω–æ–π —Å—Å—ã–ª–∫–∏