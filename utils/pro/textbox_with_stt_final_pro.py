# textbox with speech to text

import gradio as gr
import speech_recognition as sr
import numpy as np
import tempfile
import wave
import uuid
import torch
import whisper                       # OpenAI Whisper
from faster_whisper import WhisperModel  # Faster-Whisper
from typing import Union, Tuple, Optional
import gc
import threading
from nginx_manager_pro import NginxManagerPro


class TextboxWithSTTPro:
    """
    –ö–æ–º–ø–æ–Ω–µ–Ω—Ç Gradio: —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ + –≥–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–≤–∏–∂–∫–æ–≤).
    –°–æ–∑–¥–∞–≤–∞–π—Ç–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –∏ –≤—Å—Ç—Ä–∞–∏–≤–∞–π—Ç–µ –∏—Ö –≤ gr.Blocks() —á–µ—Ä–µ–∑ stt.render().
    """

    def __init__(self, **textbox_kwargs):
        self.recognizer = sr.Recognizer()

        # –ö—ç—à –º–æ–¥–µ–ª–µ–π –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        self.whisper_models = {}
        self.faster_whisper_models = {}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.fw_device = "cuda" if torch.cuda.is_available() else "cpu"
        self.fw_compute_type = "float16" if self.fw_device == "cuda" else "int8"

        self.elem_id = f"stt_textbox_{uuid.uuid4().hex[:8]}"
        self.textbox: Optional[gr.Textbox] = None
        self.render(**textbox_kwargs)

    def _save_temp_wav(self, sr_rate, y) -> str:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç np.ndarray –≤ temp wav –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å."""
        if getattr(y, "ndim", 1) > 1:
            y = y.mean(axis=1)
        tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        with wave.open(tmp.name, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(sr_rate)
            wf.writeframes((y * 32767).astype(np.int16).tobytes())
        return tmp.name
    
    def get_whisper_model(self, model_size: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç openai/whisper –º–æ–¥–µ–ª—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
        if model_size not in self.whisper_models:
            print(f"[INFO] –ó–∞–≥—Ä—É–∂–∞—é Whisper ({model_size})...")
            self.whisper_models[model_size] = whisper.load_model(model_size)
        return self.whisper_models[model_size]

    def get_faster_whisper_model(self, model_size: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç faster-whisper –º–æ–¥–µ–ª—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
        if model_size not in self.faster_whisper_models:
            print(f"[INFO] –ó–∞–≥—Ä—É–∂–∞—é Faster-Whisper ({model_size}) –Ω–∞ {self.fw_device}...")
            try:
                model = WhisperModel(model_size, device=self.fw_device, compute_type=self.fw_compute_type)
            except ValueError:
                # fallback –µ—Å–ª–∏ float16 –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
                model = WhisperModel(model_size, device=self.fw_device, compute_type="float32")
            self.faster_whisper_models[model_size] = model
        return self.faster_whisper_models[model_size]

    def cleanup_models(self):
        """–û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –ø–∞–º—è—Ç—å –æ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        if self.whisper_models:
            print("[INFO] –û—á–∏—Å—Ç–∫–∞ –º–æ–¥–µ–ª–µ–π Whisper...")
            self.whisper_models.clear()
        
        if self.faster_whisper_models:
            print("[INFO] –û—á–∏—Å—Ç–∫–∞ –º–æ–¥–µ–ª–µ–π Faster-Whisper...")
            self.faster_whisper_models.clear()
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
        gc.collect()
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CUDA
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("[INFO] –ü–∞–º—è—Ç—å GPU –æ—á–∏—â–µ–Ω–∞")

    def transcribe_audio(
        self,
        audio: Optional[Union[str, Tuple[int, np.ndarray]]],
        engine: str,
        whisper_model_size: str,
        faster_whisper_model_size: str,
        google_cloud_key: str,
        houndify_client_id: str,
        houndify_client_key: str,
        ibm_username: str,
        ibm_password: str,
        ibm_url: str,
    ) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ —Å –æ—á–∏—Å—Ç–∫–æ–π –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."""
        if audio is None:
            return "–ê—É–¥–∏–æ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ"

        try:
            # Whisper/OpenAI
            if engine == "Whisper":
                model = self.get_whisper_model(whisper_model_size)
                file_path = audio if isinstance(audio, str) else self._save_temp_wav(*audio)
                result = model.transcribe(file_path, language="ru")
                # –û—á–∏—â–∞–µ–º –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                self.cleanup_models()
                return result["text"].strip()

            # Faster-Whisper
            if engine == "Faster-Whisper":
                model = self.get_faster_whisper_model(faster_whisper_model_size)
                file_path = audio if isinstance(audio, str) else self._save_temp_wav(*audio)
                segments, _ = model.transcribe(file_path, language="ru")
                result_text = " ".join([seg.text for seg in segments]).strip()
                # –û—á–∏—â–∞–µ–º –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                self.cleanup_models()
                return result_text

            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –¥–≤–∏–∂–∫–∏ —á–µ—Ä–µ–∑ speech_recognition
            if isinstance(audio, str):
                with sr.AudioFile(audio) as source:
                    audio_data = self.recognizer.record(source)
            else:
                sr_rate, y = audio
                file_path = self._save_temp_wav(sr_rate, y)
                with sr.AudioFile(file_path) as source:
                    audio_data = self.recognizer.record(source)

            result_text = ""
            
            if engine == "Google":
                result_text = self.recognizer.recognize_google(audio_data, language="ru-RU")
            elif engine == "Google Cloud":
                if not google_cloud_key:
                    result_text = "–£–∫–∞–∂–∏—Ç–µ Google Cloud JSON –∫–ª—é—á"
                else:
                    result_text = self.recognizer.recognize_google_cloud(
                        audio_data, credentials_json=google_cloud_key, language="ru-RU"
                    )
            elif engine == "Sphinx":
                result_text = self.recognizer.recognize_sphinx(audio_data, language="ru-RU")
            elif engine == "Houndify":
                if not houndify_client_id or not houndify_client_key:
                    result_text = "–£–∫–∞–∂–∏—Ç–µ Houndify Client ID –∏ Client Key"
                else:
                    result_text = self.recognizer.recognize_houndify(
                        audio_data, client_id=houndify_client_id, client_key=houndify_client_key
                    )
            elif engine == "IBM Watson":
                if not ibm_username or not ibm_password or not ibm_url:
                    result_text = "–£–∫–∞–∂–∏—Ç–µ IBM Watson Username, Password –∏ URL"
                else:
                    result_text = self.recognizer.recognize_ibm(
                        audio_data,
                        username=ibm_username,
                        password=ibm_password,
                        url=ibm_url,
                        language="ru-RU",
                    )
            else:
                result_text = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–≤–∏–∂–æ–∫"

            # –î–ª—è –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ —Ç–æ–∂–µ –æ—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
            if engine in ["Whisper", "Faster-Whisper"]:
                self.cleanup_models()
                
            return result_text

        except sr.UnknownValueError:
            self.cleanup_models()
            return "–†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞"
        except sr.RequestError as e:
            self.cleanup_models()
            return f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}"
        except Exception as e:
            self.cleanup_models()
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"

    def delayed_cleanup(self, delay_seconds=30):
        """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ —á–µ—Ä–µ–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        def cleanup():
            import time
            time.sleep(delay_seconds)
            self.cleanup_models()
        
        cleanup_thread = threading.Thread(target=cleanup)
        cleanup_thread.daemon = True
        cleanup_thread.start()

    def insert_at_cursor(
        self,
        audio_file,
        text,
        cursor_pos,
        engine: str,
        whisper_model_size: str,
        faster_whisper_model_size: str,
        google_cloud_key: str,
        houndify_client_id: str,
        houndify_client_key: str,
        ibm_username: str,
        ibm_password: str,
        ibm_url: str,
    ):
        """–í—Å—Ç–∞–≤–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ –ø–æ–∑–∏—Ü–∏—é –∫—É—Ä—Å–æ—Ä–∞."""
        if audio_file is None:
            return text, gr.update(value=None)

        result_text = self.transcribe_audio(
            audio_file,
            engine,
            whisper_model_size,
            faster_whisper_model_size,
            google_cloud_key,
            houndify_client_id,
            houndify_client_key,
            ibm_username,
            ibm_password,
            ibm_url,
        )

        if cursor_pos is None:
            cursor_pos = len(text or "")

        base_text = text or ""
        combined = base_text[:int(cursor_pos)] + result_text + base_text[int(cursor_pos):]

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é –æ—á–∏—Å—Ç–∫—É –ø–∞–º—è—Ç–∏
        self.delayed_cleanup(delay_seconds=10)

        return combined, gr.update(value=None)

    def render(self, **textbox_kwargs) -> gr.Textbox:
        """–°–æ–∑–¥–∞—ë—Ç UI."""
        with gr.Column():
            with gr.Accordion("üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥", open=False):
                engine_dropdown = gr.Dropdown(
                    choices=[
                        "Google", "Google Cloud", "Sphinx", "Houndify", "IBM Watson",
                        "Whisper", "Faster-Whisper"
                    ],
                    value="Google",
                    label="–î–≤–∏–∂–æ–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è",
                    interactive=True,
                )

                whisper_model_dropdown = gr.Dropdown(
                    choices=["tiny", "base", "small", "medium", "large"],
                    value="base",
                    label="Whisper –º–æ–¥–µ–ª—å",
                )

                faster_whisper_model_dropdown = gr.Dropdown(
                    choices=["tiny", "base", "small", "medium", "large"],
                    value="base",
                    label="Faster-Whisper –º–æ–¥–µ–ª—å",
                )

                with gr.Accordion("üîë –ù–∞—Å—Ç—Ä–æ–π–∫–∏ API (–¥–ª—è –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤)", open=False):
                    google_cloud_key = gr.Textbox(
                        label="Google Cloud JSON –∫–ª—é—á",
                        placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ JSON –∫–ª—é—á–∞...",
                        lines=6,
                    )
                    houndify_client_id = gr.Textbox(label="Houndify Client ID")
                    houndify_client_key = gr.Textbox(label="Houndify Client Key", type="password")
                    ibm_username = gr.Textbox(label="IBM Watson Username")
                    ibm_password = gr.Textbox(label="IBM Watson Password", type="password")
                    ibm_url = gr.Textbox(
                        label="IBM Watson URL",
                        placeholder="https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/xxx",
                    )

                # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏
                cleanup_btn = gr.Button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å", size="sm")
                
                audio_input = gr.Audio(
                    sources=["microphone", "upload"],
                    type="filepath",
                    label="–ê—É–¥–∏–æ–≤—Ö–æ–¥",
                    interactive=True,
                )

                cursor_pos = gr.Number(value=0, visible=False)

        self.textbox = gr.Textbox(
            elem_id=self.elem_id,
            interactive=True,
            show_copy_button=True,
            **textbox_kwargs,
        )

        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∫–Ω–æ–ø–∫–∏ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏
        cleanup_btn.click(
            fn=lambda: print("–ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞ –≤—Ä—É—á–Ω—É—é") or self.cleanup_models(),
            inputs=[],
            outputs=[]
        )

        audio_input.change(
            fn=self.insert_at_cursor,
            inputs=[
                audio_input,
                self.textbox,
                cursor_pos,
                engine_dropdown,
                whisper_model_dropdown,
                faster_whisper_model_dropdown,
                google_cloud_key,
                houndify_client_id,
                houndify_client_key,
                ibm_username,
                ibm_password,
                ibm_url,
            ],
            outputs=[self.textbox, audio_input],
        )

        get_cursor_js = f"""
            () => {{
                const box = document.querySelector("#{self.elem_id} textarea");
                return box ? box.selectionStart : 0;
            }}
        """

        self.textbox.change(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.input(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.submit(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.focus(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.blur(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.select(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)

        return self


if __name__ == "__main__":
    nginx = NginxManagerPro(base_path="C:/")
    nginx.install_and_start()
    with gr.Blocks() as demo:
        stt = TextboxWithSTTPro(
            label="–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (—Ä–æ–ª—å –º–æ–¥–µ–ª–∏)",
            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –¢—ã - –æ–ø—ã—Ç–Ω—ã–π –ø–æ–ª–∏—Ç–æ–ª–æ–≥...",
            lines=3,
            value="–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ."
        )
    demo.launch(share=False)
