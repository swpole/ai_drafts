import gradio as gr
import speech_recognition as sr
import numpy as np
import tempfile
import wave
import uuid
from typing import Union, Tuple, Optional


class TextboxWithSTT:
    """
    –ö–æ–º–ø–æ–Ω–µ–Ω—Ç Gradio: —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ —Å –≥–æ–ª–æ—Å–æ–≤—ã–º –≤–≤–æ–¥–æ–º (STT).
    –°–æ–∑–¥–∞–≤–∞–π—Ç–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –∏ –≤—Å—Ç–∞–≤–ª—è–π—Ç–µ –≤ gr.Blocks() —á–µ—Ä–µ–∑ .render().
    """

    def __init__(self):
        self.recognizer = sr.Recognizer()
        self.elem_id = f"stt_textbox_{uuid.uuid4().hex[:8]}"
        self.textbox: Optional[gr.Textbox] = None

    def transcribe_audio(
        self,
        audio: Optional[Union[str, Tuple[int, np.ndarray]]],
        engine: str,
        google_cloud_key: str,
        houndify_client_id: str,
        houndify_client_key: str,
        ibm_username: str,
        ibm_password: str,
        ibm_url: str
    ) -> str:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º –¥–≤–∏–∂–∫–æ–º.
        """
        if audio is None:
            return "–ê—É–¥–∏–æ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ"

        try:
            # –ï—Å–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            if isinstance(audio, str):
                with sr.AudioFile(audio) as source:
                    audio_data = self.recognizer.record(source)
            else:  # (sr, np.ndarray)
                sr_rate, y = audio
                if y.ndim > 1:
                    y = y.mean(axis=1)
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                    with wave.open(tmp.name, 'wb') as wf:
                        wf.setnchannels(1)
                        wf.setsampwidth(2)
                        wf.setframerate(sr_rate)
                        wf.writeframes((y * 32767).astype(np.int16).tobytes())
                    with sr.AudioFile(tmp.name) as source:
                        audio_data = self.recognizer.record(source)

            # –í—ã–±–æ—Ä –¥–≤–∏–∂–∫–∞
            if engine == "Google":
                return self.recognizer.recognize_google(audio_data, language="ru-RU")

            if engine == "Google Cloud":
                if not google_cloud_key:
                    return "–£–∫–∞–∂–∏—Ç–µ Google Cloud JSON –∫–ª—é—á"
                return self.recognizer.recognize_google_cloud(
                    audio_data, credentials_json=google_cloud_key, language="ru-RU"
                )

            if engine == "Sphinx":
                return self.recognizer.recognize_sphinx(audio_data, language="ru-RU")

            if engine == "Houndify":
                if not houndify_client_id or not houndify_client_key:
                    return "–£–∫–∞–∂–∏—Ç–µ Houndify Client ID –∏ Client Key"
                return self.recognizer.recognize_houndify(
                    audio_data, client_id=houndify_client_id, client_key=houndify_client_key
                )

            if engine == "IBM Watson":
                if not ibm_username or not ibm_password or not ibm_url:
                    return "–£–∫–∞–∂–∏—Ç–µ IBM Watson Username, Password –∏ URL"
                return self.recognizer.recognize_ibm(
                    audio_data,
                    username=ibm_username,
                    password=ibm_password,
                    url=ibm_url,
                    language="ru-RU"
                )

            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–≤–∏–∂–æ–∫"

        except sr.UnknownValueError:
            return "–†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞"
        except sr.RequestError as e:
            return f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}"
        except Exception as e:
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"

    def insert_at_cursor(
        self,
        audio_file,
        text,
        cursor_pos,
        engine: str,
        google_cloud_key: str,
        houndify_client_id: str,
        houndify_client_key: str,
        ibm_username: str,
        ibm_password: str,
        ibm_url: str
    ):
        if audio_file is None:
            return text, gr.update(value=None)

        result = self.transcribe_audio(
            audio_file,
            engine,
            google_cloud_key,
            houndify_client_id,
            houndify_client_key,
            ibm_username,
            ibm_password,
            ibm_url
        )

        if cursor_pos is None:
            cursor_pos = len(text or "")
        base_text = text or ""
        combined = base_text[:int(cursor_pos)] + result + base_text[int(cursor_pos):]

        return combined, gr.update(value=None)

    def render(self) -> gr.Textbox:
        """
        –°–æ–∑–¥–∞—ë—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—É—â–µ–≥–æ gr.Blocks() –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç gr.Textbox.
        """
        with gr.Accordion("üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥", open=False):
            engine_dropdown = gr.Dropdown(
                choices=["Google", "Google Cloud", "Sphinx", "Houndify", "IBM Watson"],
                value="Google",
                label="–î–≤–∏–∂–æ–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è",
                interactive=True
            )

            with gr.Accordion("üîë –ù–∞—Å—Ç—Ä–æ–π–∫–∏ API (–¥–ª—è –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤)", open=False):
                google_cloud_key = gr.Textbox(
                    label="Google Cloud JSON –∫–ª—é—á",
                    placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ JSON –∫–ª—é—á–∞...",
                    lines=6
                )
                houndify_client_id = gr.Textbox(label="Houndify Client ID")
                houndify_client_key = gr.Textbox(label="Houndify Client Key", type="password")
                ibm_username = gr.Textbox(label="IBM Watson Username")
                ibm_password = gr.Textbox(label="IBM Watson Password", type="password")
                ibm_url = gr.Textbox(
                    label="IBM Watson URL",
                    placeholder="https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/xxx"
                )

            audio_input = gr.Audio(
                sources=["microphone", "upload"],
                type="filepath",
                label="–ê—É–¥–∏–æ–≤—Ö–æ–¥",
                interactive=True
            )

            cursor_pos = gr.Number(value=0, visible=False)

        self.textbox = gr.Textbox(
            placeholder="–ü–æ—Å—Ç–∞–≤—å—Ç–µ –∫—É—Ä—Å–æ—Ä –≤ –Ω—É–∂–Ω–æ–µ –º–µ—Å—Ç–æ –∏ –¥–æ–±–∞–≤—å—Ç–µ –∞—É–¥–∏–æ...",
            lines=4,
            max_lines=10,
            interactive=True,
            show_copy_button=True,
            elem_id=self.elem_id
        )

        # —Å–æ–±—ã—Ç–∏—è
        audio_input.change(
            fn=self.insert_at_cursor,
            inputs=[
                audio_input, self.textbox, cursor_pos,
                engine_dropdown,
                google_cloud_key,
                houndify_client_id,
                houndify_client_key,
                ibm_username,
                ibm_password,
                ibm_url
            ],
            outputs=[self.textbox, audio_input]
        )

        # JS –¥–ª—è –∫—É—Ä—Å–æ—Ä–∞
        get_cursor_js = f"""
            () => {{
                const box = document.querySelector("#{self.elem_id} textarea");
                return box ? box.selectionStart : 0;
            }}
        """
        self.textbox.input(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.change(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.submit(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.focus(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.blur(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)
        self.textbox.select(fn=None, inputs=None, outputs=cursor_pos, js=get_cursor_js)

        return self.textbox

    def launch(self, **kwargs):
        """–ó–∞–ø—É—Å–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        with gr.Blocks() as demo:
            self.render()
        demo.launch(**kwargs)

if __name__ == "__main__":
    app = TextboxWithSTT()
    app.launch(share=False)