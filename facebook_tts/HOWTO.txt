Привет! Сегодня я расскажу как озвучить текст. Мы будем сочинять код для простого железа. Для продвинутого железа смотрите видео про VibeVoice.
На этот раз нам будет помогать DeepSeek.
К сожалению ни DeepSeek, ни ChatGPT не смогли помочь с самого начала. Поэтому мне пришлось помочь и закинуть простейший код.
Я нашёл прототип этого кода на hugging face. Отфильтровал text-to-speach модели на содержание "ru" и отсортировал по загрузкам.
Код работал, но была ошибка при сохранении файла.
С этого места подключился DeepSeek.
У меня есть код, который преобразует текст в речь. Как сохранить результат в файл. Вот этот код:
import torch
import scipy

model = VitsModel.from_pretrained("facebook/mms-tts-rus")
tokenizer = AutoTokenizer.from_pretrained("facebook/mms-tts-rus")

text = "some example text in the Russian language"
inputs = tokenizer(text, return_tensors="pt")

with torch.no_grad():
    output = model(**inputs).waveform
	
Чтобы сохранить результат преобразования текста в речь в файл, вы можете использовать библиотеку scipy.io.wavfile. Вот модифицированный код:
import torch
from scipy.io import wavfile
from transformers import VitsModel, AutoTokenizer

model = VitsModel.from_pretrained("facebook/mms-tts-rus")
tokenizer = AutoTokenizer.from_pretrained("facebook/mms-tts-rus")

text = "some example text in the Russian language"
inputs = tokenizer(text, return_tensors="pt")

with torch.no_grad():
    output = model(**inputs).waveform

# Преобразуем тензор в numpy массив и нормализуем
audio = output.cpu().numpy()
audio = audio.squeeze()  # Убираем лишние измерения
audio = (audio * 32767).astype('int16')  # Нормализуем для 16-битного WAV

# Сохраняем в WAV файл
sample_rate = model.config.sampling_rate
wavfile.write("output_audio.wav", sample_rate, audio)

print("Аудио сохранено в файл: output_audio.wav")

Давай сделаем из этого кода класс, при вызове которого можно будет задать текст, модель и другие параметры, чтобы сгенерировать речь.

Отличная идея! Вот реализация класса для генерации речи с гибкими параметрами:

Также вот упрощенная версия класса, если нужен минималистичный вариант:

Отлично! Расширенный выриант работает без проблем. Давай будем использовать его. Сделай код, который в gradio преобразует заданный текст в речь, используя заданную модель, которую можно выбрать из списка.

Отлично! Вот код с Gradio интерфейсом для преобразования текста в речь с выбором модели:

Также создадим упрощенную версию для быстрого запуска:

Заводится с одного касания! Качество, конечно не очень. Попробуем другую модель.
К сожалению в поиске модели DeepSeek не помощник.
Приходится просматривать модели и искать те, в которых есть русский язык и такой же вызов.
Я нашёл, например, эту.
Вносим её в список и подправляем код, потому что для неё необходимо указать speaker_id.
output = self.model(**inputs, speaker_id=1).waveform

Итак, мы получили инструмент для преобразования текста в речь. Качество, конечно, не очень, но для отладки пойдёт. Если кто-нибудь найдёт модель, которая тоже работает с этой программой - поделитесь с другими в комментариях.
В следующем видео мы создадим более качественного диктора. Но для него потребуется серьёзная видео-карта.